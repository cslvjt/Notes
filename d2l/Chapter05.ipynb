{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 层和块\n",
    "+ 层(layer)：卷积层、线性映射层....\n",
    "+ 块(block)：由许多层组成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 块结构\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden=nn.Linear(20,256)\n",
    "        self.out=nn.Linear(256,10)\n",
    "    def forward(self,X):\n",
    "        y=self.hidden(X)\n",
    "        y=self.out(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 参数管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数访问\n",
    "import torch\n",
    "from torch import nn\n",
    "net=nn.Sequential(\n",
    "    nn.Linear(4,8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8,1)\n",
    ")\n",
    "print(net[2].state_dict())\n",
    "print(net[2].bias) #tensor([0.1111],requires_grad=True)\n",
    "print(net[2].bias.data) # tensor([0.1629])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一次性访问\n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数初始化\n",
    "def xavier(m):\n",
    "    nn.init.xavier_uniform_(m.weight)\n",
    "net.apply(xavier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数绑定\n",
    "#将层提前定义，然后插入\n",
    "shared=nn.Linear(8,8)\n",
    "net=nn.Sequential(\n",
    "    nn.Linear(4,8),\n",
    "    nn.ReLU(),\n",
    "    shared,\n",
    "    nn.ReLU(),\n",
    "    shared,\n",
    "    nn.Linear(8,1)\n",
    ")\n",
    "# 由于模型参数包含梯度，\n",
    "# 因此在反向传播期间第二个隐藏层和第三个隐藏层的梯度会加在一起。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读写文件\n",
    "+ 保存和加载张量\n",
    "  ```\n",
    "  import torch\n",
    "  x=torch.arange(4)\n",
    "  torch.save(x,'x-file')\n",
    "  x2=torch.load('x-file')\n",
    "  ```\n",
    "+ 加载和保存模型参数\n",
    "  ```\n",
    "  import torch\n",
    "  import torch.nn as nn\n",
    "  class MLP(nn.Module):\n",
    "      def __init__(self):\n",
    "          super().__init__()\n",
    "          self.hidden=nn.Linear(20,256)\n",
    "          self.out=nn.Linear(256,10)\n",
    "      def forward(self,X):\n",
    "          y=self.hidden(X)\n",
    "          y=self.out(y)\n",
    "          return y\n",
    "  net=MLP()\n",
    "  torch.save(net.state_dict(),'mlp.params')\n",
    "  clone_mlp=MLP()\n",
    "  clone.load_state_dict(torch.load('mlp.params'))\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 GPU的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本操作\n",
    "import torch\n",
    "torch.device('cpu') #使用cpu\n",
    "torch.cuda.device('cuda') # 使用GPU\n",
    "torch.cuda.device('cuda:1')\n",
    "#查询GPU数量\n",
    "torch.cuda.device_count()\n",
    "# 使用指定型号的GPU\n",
    "def try_gpu(index=0):\n",
    "    if torch.cuda.device_count()>=index+1:\n",
    "        return torch.device(f\"cuda{index}\")\n",
    "    return torch.device('cpu')\n",
    "# 使用所有GPU\n",
    "def try_all_gpus():\n",
    "    devices=[torch.device(f\"cuda:{i}\") for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用GPU\n",
    "## 张量\n",
    "X=torch.ones(2,3,device=try_all_gpus())\n",
    "## 模型\n",
    "net=nn.Sequential(nn.Linear(3,1))\n",
    "net=net.to(device=try_all_gpus())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1be8e1e697be24aa51be46f7515f4d96c6005120fc689094ce96895b044c9b1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
